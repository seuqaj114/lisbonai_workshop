{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal of this workshop\n",
    "The goal of this workshop is to give you a thourough understanding of Tensorflow and how you can use it to effectively build and train neural network models.\n",
    "\n",
    "We will not be running big models since we have limited time and hardware, but hopefully this will give you the skills and tools to go home later and confidently start running different experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start by importing some standard libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[], name=\"x\")\n",
    "y = x + 2\n",
    "\n",
    "session = tf.Session()\n",
    "\n",
    "result = session.run(y, feed_dict={x: 3})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since both y and x are nodes in the graph, we can \"ask\" for both of them in the output of session.run (this does not run the graph twice!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 7.0\n",
      "x = 5.0\n"
     ]
    }
   ],
   "source": [
    "result = session.run([y, x], feed_dict={x: 5})\n",
    "print(\"y = {}\".format(result[0]))\n",
    "print(\"x = {}\".format(result[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's say we want a linear model, so we have some input $x$ and the output is given by $y = x^T \\theta$. Let's put that into a function called _linear_, which receives an input $x$ and parameters $\\theta$ and return $y$. Make the input $x$ a 3-dimensional vector and use a constant variable $\\theta$ by using tf.constant(value).\n",
    "\n",
    "Given info:\n",
    "    remember that $x^T \\theta = \\sum_i x_i \\cdot \\theta_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 6.0\n"
     ]
    }
   ],
   "source": [
    "def linear(x, theta):\n",
    "    return tf.reduce_sum(tf.multiply(theta, x), axis=0)\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[3], name=\"x\")\n",
    "theta = tf.constant(np.array([1.,1.,1.], dtype=np.float32), name=\"theta\")\n",
    "y = linear(x, theta)\n",
    "\n",
    "session = tf.Session()\n",
    "\n",
    "result = session.run(y, feed_dict={x: np.array([1.,2.,3.])})\n",
    "print(\"y = {}\".format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so at this point we have a function that can take one input and return its output according to a simple linear model. However, we usually want to pass many inputs at the same time (this is what we call a batch), and get all the outputs. So let's change our placeholder in order for it to accept 4 input vectors (lets make x a 4x3 placeholder). Remember we now want our output to have 4 elements, one for each input array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = [  6.  15.  24.  33.]\n"
     ]
    }
   ],
   "source": [
    "def linear(x, theta):\n",
    "    return tf.reduce_sum(tf.multiply(x, theta), axis=1)\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[4, 3], name=\"x\")\n",
    "theta = tf.constant(np.array([1.,1.,1.], dtype=np.float32), name=\"theta\")\n",
    "y = linear(x, theta)\n",
    "\n",
    "session = tf.Session()\n",
    "\n",
    "result = session.run(y, feed_dict={x: np.array([[1,2,3], [4,5,6], [7,8,9], [10,11,12]])})\n",
    "print(\"y = {}\".format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we also want the outputs to have higher dimension than 1, so let's make our outputs are 2 dimensional. This means that now $\\theta$ is not a vector but a input_dim x out_dim matrix, so 3x2 in this case. So go ahead and change the matrix accordingly and check if the results are correct. Your $y$ now should be 4x2 dimensional.\n",
    "\n",
    "Also, using tf.reduce_sum and tf.multiply is ugly and won't work in this case, so let's use what we should have been using in the first place: tf.matmul, which multiplies two matrices, which is what we want!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = [[  6.  12.]\n",
      " [ 15.  30.]\n",
      " [ 24.  48.]\n",
      " [ 33.  66.]]\n"
     ]
    }
   ],
   "source": [
    "def linear(x, theta):\n",
    "    return tf.matmul(x, theta)\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[4, 3], name=\"x\")\n",
    "theta = tf.constant(np.array([[1,2],[1,2],[1,2]], dtype=np.float32), name=\"theta\")\n",
    "y = linear(x, theta)\n",
    "\n",
    "session = tf.Session()\n",
    "\n",
    "result = session.run(y, feed_dict={x: np.array([[1,2,3], [4,5,6], [7,8,9], [10,11,12]])})\n",
    "print(\"y = {}\".format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see we are heading towards a linear regression implementation here. We have a linear model, our inputs, outputs, and parameters. However, we need a few more things before we can make it learn.\n",
    "\n",
    "First of all we need targets, right? For linear regression we have our inputs, but we also have a set of target outputs, to which the model's outputs $y$ must be close. So let's create another placeholder which will receive the target outputs and compute the squared difference between that and the model's output for each item in the batch. __I will provide some data here__ Remember target outputs are supposed to be the same shape as the model's outputs, so that we can compute their difference. Also, change session.run so that it returns the cost and not the outputs y.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = [   45.     281.25   720.    1361.25]\n"
     ]
    }
   ],
   "source": [
    "def linear(x, theta):\n",
    "    return tf.matmul(x, theta)\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[4, 3], name=\"x\")\n",
    "theta = tf.constant(np.array([[1,2],[1,2],[1,2]], dtype=np.float32), name=\"theta\")\n",
    "y = linear(x, theta)\n",
    "\n",
    "target = tf.placeholder(tf.float32, shape=[4, 2], name=\"target\")\n",
    "\n",
    "cost = tf.reduce_sum(tf.square(y-target), axis=1)\n",
    "\n",
    "session = tf.Session()\n",
    "\n",
    "feed_dict = {\n",
    "    x: np.array([[1,2,3], [4,5,6], [7,8,9], [10,11,12]]),\n",
    "    target: np.array([[3,6], [7.5, 15], [12, 24], [16.5, 33]])\n",
    "}\n",
    "result = session.run(cost, feed_dict=feed_dict)\n",
    "print(\"cost = {}\".format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing we are missing we that the parameters $\\theta$ that we want to optimized are defined as a constant in the graph, so we can change it! What we want is to define $\\theta$ as a variable instead: tf.Variable.\n",
    "One thing we have to bear in mind is that unlike the constant, a Variable node has no value before it is initialized (its like being empty). So we have to run session.run(theta.initializer) before running operations that depend on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = [   45.     281.25   720.    1361.25]\n"
     ]
    }
   ],
   "source": [
    "def linear(x, theta):\n",
    "    return tf.matmul(x, theta)\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[4, 3], name=\"x\")\n",
    "theta = tf.Variable(np.array([[1,2],[1,2],[1,2]], dtype=np.float32), name=\"theta\")\n",
    "y = linear(x, theta)\n",
    "\n",
    "target = tf.placeholder(tf.float32, shape=[4, 2], name=\"target\")\n",
    "\n",
    "cost = tf.reduce_sum(tf.square(y-target), axis=1)\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(theta.initializer)\n",
    "\n",
    "feed_dict = {\n",
    "    x: np.array([[1,2,3], [4,5,6], [7,8,9], [10,11,12]]),\n",
    "    target: np.array([[3,6], [7.5, 15], [12, 24], [16.5, 33]])\n",
    "}\n",
    "result = session.run(cost, feed_dict=feed_dict)\n",
    "print(\"cost = {}\".format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we have inputs, outputs, targets, parameters and the cost. What else do we need? We need to know how to change $\\theta$ in order to make the cost smaller. \n",
    "__Explain what the cost is here, and how to perform gradient descent__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x, theta):\n",
    "    return tf.matmul(x, theta)\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[4, 3], name=\"x\")\n",
    "theta = tf.Variable(np.array([[1,2],[1,2],[1,2]], dtype=np.float32), name=\"theta\")\n",
    "y = linear(x, theta)\n",
    "\n",
    "target = tf.placeholder(tf.float32, shape=[4, 2], name=\"target\")\n",
    "\n",
    "cost = tf.reduce_mean(tf.reduce_sum(tf.square(y-target), axis=1))\n",
    "gradient = tf.gradients(cost, theta)\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(theta.initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = 601.875\n",
      "gradient = [array([[ 141. ,  282. ],\n",
      "       [ 160.5,  321. ],\n",
      "       [ 180. ,  360. ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "feed_dict = {\n",
    "    x: np.array([[1,2,3], [4,5,6], [7,8,9], [10,11,12]]),\n",
    "    target: np.array([[3,6], [7.5, 15], [12, 24], [16.5, 33]])\n",
    "}\n",
    "result = session.run([cost, gradient], feed_dict=feed_dict)\n",
    "print(\"cost = {}\".format(result[0]))\n",
    "print(\"gradient = {}\".format(result[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to update our variable $\\theta$. Since Variables are special in that their value does not depend on the input, and if we change their value we want it to remain for the next sess.run's, there are special method to update them. So, according to gradient descent we want to perform __formula__\n",
    "We can change the value using tf.assign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x, theta):\n",
    "    return tf.matmul(x, theta)\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[4, 3], name=\"x\")\n",
    "theta = tf.Variable(np.array([[1,2],[1,2],[1,2]], dtype=np.float32), name=\"theta\")\n",
    "y = linear(x, theta)\n",
    "\n",
    "target = tf.placeholder(tf.float32, shape=[4, 2], name=\"target\")\n",
    "\n",
    "cost = tf.reduce_mean(tf.reduce_sum(tf.square(y-target), axis=1))\n",
    "gradient = tf.gradients(cost, [theta])\n",
    "\n",
    "update_op = tf.assign(theta, theta - 0.001 * gradient[0])\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(theta.initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = 601.875\n",
      "gradient = [array([[ 141. ,  282. ],\n",
      "       [ 160.5,  321. ],\n",
      "       [ 180. ,  360. ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "feed_dict = {\n",
    "    x: np.array([[1,2,3], [4,5,6], [7,8,9], [10,11,12]]),\n",
    "    target: np.array([[3,6], [7.5, 15], [12, 24], [16.5, 33]])\n",
    "}\n",
    "result = session.run([cost, gradient, update_op], feed_dict=feed_dict)\n",
    "print(\"cost = {}\".format(result[0]))\n",
    "print(\"gradient = {}\".format(result[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't want to press enter everytime, let's put this session.run cell into a for loop and run it for, say, 20 iterations, printing out the cost (you don't need to print the gradient)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x, theta):\n",
    "    return tf.matmul(x, theta)\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[4, 3], name=\"x\")\n",
    "theta = tf.Variable(np.array([[1,2],[1,2],[1,2]], dtype=np.float32), name=\"theta\")\n",
    "y = linear(x, theta)\n",
    "\n",
    "target = tf.placeholder(tf.float32, shape=[4, 2], name=\"target\")\n",
    "\n",
    "cost = tf.reduce_mean(tf.reduce_sum(tf.square(y-target), axis=1))\n",
    "gradient = tf.gradients(cost, [theta])\n",
    "\n",
    "update_op = tf.assign(theta, theta - gradient[0])\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(theta.initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = 601.8750\n",
      "cost = 62856404.0000\n",
      "cost = 6564532453376.0000\n",
      "cost = 685579859656704000.0000\n",
      "cost = 71599879696999390380032.0000\n",
      "cost = 7477674298894095899139506176.0000\n",
      "cost = 780945653460402238085653860450304.0000\n",
      "cost = 81559605215794493457106262924076253184.0000\n",
      "cost = inf\n",
      "cost = inf\n",
      "cost = inf\n",
      "cost = inf\n",
      "cost = inf\n",
      "cost = inf\n",
      "cost = inf\n",
      "cost = inf\n",
      "cost = inf\n",
      "cost = nan\n",
      "cost = nan\n",
      "cost = nan\n"
     ]
    }
   ],
   "source": [
    "feed_dict = {\n",
    "    x: np.array([[1,2,3], [4,5,6], [7,8,9], [10,11,12]]),\n",
    "    target: np.array([[3,6], [7.5, 15], [12, 24], [16.5, 33]])\n",
    "}\n",
    "\n",
    "for i in range(20):\n",
    "    result = session.run([cost, gradient, update_op], feed_dict=feed_dict)\n",
    "    print(\"cost = {:.4f}\".format(result[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh no, our cost is going up! Does anyone know why that is happening?\n",
    "__lengthy discussion about learning rate here__\n",
    "We need to use a smaller learning rate, so go ahead and multiply the gradient by a small number until you find one that makes the cost go to zero. (settle for 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear(x, theta):\n",
    "    return tf.matmul(x, theta)\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[4, 3], name=\"x\")\n",
    "theta = tf.Variable(np.array([[1,2],[1,2],[1,2]], dtype=np.float32), name=\"theta\")\n",
    "y = linear(x, theta)\n",
    "\n",
    "target = tf.placeholder(tf.float32, shape=[4, 2], name=\"target\")\n",
    "\n",
    "cost = tf.reduce_mean(tf.reduce_sum(tf.square(y-target), axis=1))\n",
    "gradient = tf.gradients(cost, [theta])\n",
    "\n",
    "update_op = tf.assign(theta, theta - 0.001*gradient[0])\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(theta.initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = 601.8750\n",
      "cost = 274.9148\n",
      "cost = 125.5756\n",
      "cost = 57.3649\n",
      "cost = 26.2097\n",
      "cost = 11.9795\n",
      "cost = 5.4799\n",
      "cost = 2.5111\n",
      "cost = 1.1551\n",
      "cost = 0.5358\n",
      "cost = 0.2529\n",
      "cost = 0.1237\n",
      "cost = 0.0646\n",
      "cost = 0.0376\n",
      "cost = 0.0253\n",
      "cost = 0.0196\n",
      "cost = 0.0171\n",
      "cost = 0.0159\n",
      "cost = 0.0153\n",
      "cost = 0.0150\n"
     ]
    }
   ],
   "source": [
    "feed_dict = {\n",
    "    x: np.array([[1,2,3], [4,5,6], [7,8,9], [10,11,12]]),\n",
    "    target: np.array([[3,6], [7.5, 15], [12, 24], [16.5, 33]])\n",
    "}\n",
    "\n",
    "for i in range(20):\n",
    "    result = session.run([cost, gradient, update_op], feed_dict=feed_dict)\n",
    "    print(\"cost = {:.4f}\".format(result[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there it is, you just implemented your own linear regression in Tensorflow! Pat yourselves in the back and let's get right into using this to build neural networks.\n",
    "\n",
    "First of all, we need a better dataset, this one is not even real! So to start off, we are going to use the Iris petal dataset __describe dataset__\n",
    "This is a classification problem, and right now what we are doing is regression, so before we start using our actual dataset let's see how we can change our code to perform classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x, theta):\n",
    "    return tf.matmul(x, theta)\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[4, 3], name=\"x\")\n",
    "theta = tf.Variable(np.array([[1,2],[1,2],[1,2]], dtype=np.float32), name=\"theta\")\n",
    "y = tf.nn.softmax(linear(x, theta), 1)\n",
    "\n",
    "target = tf.placeholder(tf.float32, shape=[4, 2], name=\"target\")\n",
    "\n",
    "cost = tf.reduce_mean(tf.reduce_sum(tf.square(y-target), axis=1))\n",
    "gradient = tf.gradients(cost, [theta])\n",
    "\n",
    "update_op = tf.assign(theta, theta - 0.001*gradient[0])\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(theta.initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = 1.5000\n",
      "[array([[  4.8748e-06,  -4.7874e-06],\n",
      "       [  1.0668e-05,  -1.0558e-05],\n",
      "       [  1.6460e-05,  -1.6329e-05]], dtype=float32)]\n",
      "cost = 1.5000\n",
      "[array([[  4.8748e-06,  -4.7874e-06],\n",
      "       [  1.0668e-05,  -1.0558e-05],\n",
      "       [  1.6460e-05,  -1.6329e-05]], dtype=float32)]\n",
      "cost = 1.5000\n",
      "[array([[  4.8748e-06,  -4.7874e-06],\n",
      "       [  1.0668e-05,  -1.0558e-05],\n",
      "       [  1.6460e-05,  -1.6329e-05]], dtype=float32)]\n",
      "cost = 1.5000\n",
      "[array([[  4.8748e-06,  -4.7874e-06],\n",
      "       [  1.0668e-05,  -1.0558e-05],\n",
      "       [  1.6460e-05,  -1.6329e-05]], dtype=float32)]\n",
      "cost = 1.5000\n",
      "[array([[  4.8748e-06,  -4.7874e-06],\n",
      "       [  1.0668e-05,  -1.0558e-05],\n",
      "       [  1.6460e-05,  -1.6329e-05]], dtype=float32)]\n",
      "cost = 1.5000\n",
      "[array([[  4.8748e-06,  -4.7874e-06],\n",
      "       [  1.0668e-05,  -1.0558e-05],\n",
      "       [  1.6460e-05,  -1.6329e-05]], dtype=float32)]\n",
      "cost = 1.5000\n",
      "[array([[  4.8748e-06,  -4.7874e-06],\n",
      "       [  1.0668e-05,  -1.0558e-05],\n",
      "       [  1.6460e-05,  -1.6329e-05]], dtype=float32)]\n",
      "cost = 1.5000\n",
      "[array([[  4.8748e-06,  -4.7874e-06],\n",
      "       [  1.0668e-05,  -1.0558e-05],\n",
      "       [  1.6460e-05,  -1.6329e-05]], dtype=float32)]\n",
      "cost = 1.5000\n",
      "[array([[  4.8748e-06,  -4.7874e-06],\n",
      "       [  1.0668e-05,  -1.0558e-05],\n",
      "       [  1.6460e-05,  -1.6329e-05]], dtype=float32)]\n",
      "cost = 1.5000\n",
      "[array([[  4.8748e-06,  -4.7874e-06],\n",
      "       [  1.0668e-05,  -1.0558e-05],\n",
      "       [  1.6460e-05,  -1.6329e-05]], dtype=float32)]\n",
      "cost = 1.5000\n",
      "[array([[  4.8748e-06,  -4.7874e-06],\n",
      "       [  1.0668e-05,  -1.0558e-05],\n",
      "       [  1.6460e-05,  -1.6329e-05]], dtype=float32)]\n",
      "cost = 1.5000\n",
      "[array([[  4.8748e-06,  -4.7874e-06],\n",
      "       [  1.0668e-05,  -1.0558e-05],\n",
      "       [  1.6460e-05,  -1.6329e-05]], dtype=float32)]\n",
      "cost = 1.5000\n",
      "[array([[  4.8748e-06,  -4.7874e-06],\n",
      "       [  1.0668e-05,  -1.0558e-05],\n",
      "       [  1.6460e-05,  -1.6329e-05]], dtype=float32)]\n",
      "cost = 1.5000\n",
      "[array([[  4.8748e-06,  -4.7874e-06],\n",
      "       [  1.0668e-05,  -1.0558e-05],\n",
      "       [  1.6460e-05,  -1.6329e-05]], dtype=float32)]\n",
      "cost = 1.5000\n",
      "[array([[  4.8748e-06,  -4.7874e-06],\n",
      "       [  1.0668e-05,  -1.0558e-05],\n",
      "       [  1.6460e-05,  -1.6329e-05]], dtype=float32)]\n",
      "cost = 1.5000\n",
      "[array([[  4.8748e-06,  -4.7874e-06],\n",
      "       [  1.0668e-05,  -1.0558e-05],\n",
      "       [  1.6460e-05,  -1.6329e-05]], dtype=float32)]\n",
      "cost = 1.5000\n",
      "[array([[  4.8748e-06,  -4.7874e-06],\n",
      "       [  1.0668e-05,  -1.0558e-05],\n",
      "       [  1.6460e-05,  -1.6329e-05]], dtype=float32)]\n",
      "cost = 1.5000\n",
      "[array([[  4.8748e-06,  -4.7874e-06],\n",
      "       [  1.0668e-05,  -1.0558e-05],\n",
      "       [  1.6460e-05,  -1.6329e-05]], dtype=float32)]\n",
      "cost = 1.5000\n",
      "[array([[  4.8748e-06,  -4.7874e-06],\n",
      "       [  1.0668e-05,  -1.0558e-05],\n",
      "       [  1.6460e-05,  -1.6329e-05]], dtype=float32)]\n",
      "cost = 1.5000\n",
      "[array([[  4.8748e-06,  -4.7874e-06],\n",
      "       [  1.0668e-05,  -1.0558e-05],\n",
      "       [  1.6460e-05,  -1.6329e-05]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "feed_dict = {\n",
    "    x: np.array([[1,2,3], [4,5,6], [7,8,9], [10,11,12]]),\n",
    "    target: np.array([[0,1], [1, 0], [1, 0], [1, 0]])\n",
    "}\n",
    "\n",
    "for i in range(20):\n",
    "    result = session.run([cost, gradient, update_op], feed_dict=feed_dict)\n",
    "    print(\"cost = {:.4f}\".format(result[0]))\n",
    "    print(result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
